{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center><big>Semi-supervised learning : le pseudo-labeling</big> <br></center></h1>\n",
        "\n",
        "<h3><center>Expérimentations sur CIFAR10</center></h3>\n",
        "<hr>"
      ],
      "metadata": {
        "id": "u9Miw4Hoq8ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous avons adapté le tutoriel pytorch pour faire du semi-supervisé :\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "\n",
        "Nous utiliserons CIFAR10, un jeu de données de petites images couleur de 32x32 pixels avec 10 classes différentes.\n",
        "\n",
        "L'ensemble d'entraînement compte normalement 50 000 images et l'ensemble de test 10 000 images.\n",
        "\n",
        "Ce jeu de données est entièrement annoté, nous allons donc supprimer artificiellement certaines étiquettes."
      ],
      "metadata": {
        "id": "wio_DnHArvxn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7_Y1pVOqZRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e09d375-8a75-474c-e1b5-97ba4c58bb4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 18 13:27:14 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0    30W /  70W |   1136MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm_notebook"
      ],
      "metadata": {
        "id": "Qw7EHo7QtRwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour la reproductibilité :"
      ],
      "metadata": {
        "id": "riLsOGHtxXAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED=2023\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "cudnn.benchmark = True\n",
        "np.random.seed(SEED)\n",
        "# random.seed(SEED)\n"
      ],
      "metadata": {
        "id": "YjPMVxLzwmmX",
        "outputId": "378c1732-6a43-46d6-87e4-24c0ea4e8e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-5b23b43811dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSEED\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2023\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: false INTERNAL ASSERT FAILED at \"../c10/cuda/CUDAGraphsC10Utils.h\":73, please report a bug to PyTorch. Unknown CUDA graph CaptureStatus32767"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "2kXKMo4TCQMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement de CIFAR10"
      ],
      "metadata": {
        "id": "VQD3IKqYtDKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "gtQT07nPtIqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(images, labels, predicted_labels=None):\n",
        "    # Using torchvision to make a grid of the images\n",
        "    img = torchvision.utils.make_grid(images)\n",
        "\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    img = img.permute(1, 2, 0)\n",
        "\n",
        "    # Plotting the grid\n",
        "    fig, ax = plt.subplots(figsize=(12, 48))\n",
        "    plt.imshow(img)\n",
        "\n",
        "    if predicted_labels is not None:\n",
        "        # labels prédits si elles existent\n",
        "        ax.set_xlabel('Predicted labels', fontsize=18, labelpad=12)\n",
        "        ax.set_xticks(torch.arange(len(images)) * 35 + 20)\n",
        "        ax.set_xticklabels([classes[predicted_labels[j]]\n",
        "                            for j in range(len(images))], fontsize=14)\n",
        "\n",
        "    # labels ground truth\n",
        "    gax = ax.secondary_xaxis('top')\n",
        "    gax.set_xlabel('Ground truth', fontsize=18, labelpad=12)\n",
        "    gax.set_xticks(torch.arange(len(images)) * 35 + 20)\n",
        "    gax.set_xticklabels([classes[labels[j]]\n",
        "                         for j in range(len(images))], fontsize=14)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LZPz-coGtVkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Images random du train\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "et42cFqdvAkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(images[:4], labels[:4])"
      ],
      "metadata": {
        "id": "vMFppVrRvP5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split artificiel du train"
      ],
      "metadata": {
        "id": "5HaKEWdPvyLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divisons l'ensemble des données de train en :\n",
        "\n",
        "\n",
        "* exemples avec label\n",
        "* exemples sans label\n",
        "\n",
        "Comme les données sont entièrement étiquetées, nous supprimons artificiellement certaines étiquettes et leur attribuons la valeur -1.\n",
        "\n"
      ],
      "metadata": {
        "id": "8iLZh6VOv53D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nous ne gardons que 40% de l'ensemble des données étiquetées du train\n",
        "# Vous pourrez essayer une autre valeur par la suite\n",
        "# A priori que se passe-t-il si cette valeur est très faible ? Très élevée ?\n",
        "\n",
        "proportion_labeled_elements = 0.2\n",
        "\n",
        "# on shuffle les indices :\n",
        "indices = torch.randperm(len(trainset))\n",
        "\n",
        "n_labeled_indices = int(len(indices) * proportion_labeled_elements)\n",
        "indices_labeled = sorted(indices[:n_labeled_indices])\n",
        "indices_unlabeled = sorted(indices[n_labeled_indices:])\n",
        "\n",
        "for index in indices_unlabeled:\n",
        "    trainset.targets[index] = -1  # on met à -1 le label (valeur arbitraire, on la remplacera pour un label prédit par la suite)\n",
        "\n",
        "dataset_train_labeled = torch.utils.data.Subset(trainset, indices_labeled)\n",
        "dataset_train_unlabeled = torch.utils.data.Subset(trainset, indices_unlabeled)\n"
      ],
      "metadata": {
        "id": "p0xzgHtwvTe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_train_labeled), len(dataset_train_unlabeled)"
      ],
      "metadata": {
        "id": "I362Rs0Z77p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_labeled = torch.utils.data.DataLoader(dataset_train_labeled, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Pas de shuffle sur la data loader des unlabeled, sinon on ne pourra pas les remplacer facilement par des labels prédits\n",
        "train_loader_unlabeled = torch.utils.data.DataLoader(dataset_train_unlabeled, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "LytR-74k8Bbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Définition d'un petit CNN"
      ],
      "metadata": {
        "id": "66M-XZgzAfG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pourrez par la suite essayer un modèle standard, comme un ResNet, pré-entraîné sur ImageNet ou non.\n",
        "\n",
        "Voir si le pseudo-labeling que l'on fait ici avec un tout petit modèle marche aussi avec un plus gros modèle comme ResNet.\n",
        ""
      ],
      "metadata": {
        "id": "Tntly0rzAh1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GC3ZVljxAZtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(testloader, trainloader, model, opt, crit, n_epoch=2, loss_every=500):\n",
        "    \"\"\"\n",
        "    Entraînement d'un modèle et plot des courbes de loss et accuracy\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    losses = []\n",
        "    acc = []\n",
        "    for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "        print(f\"Epoch {epoch}.\")\n",
        "\n",
        "        running_loss = []\n",
        "        running_acc = []\n",
        "        print(\"Train.\")\n",
        "        for i, data in tqdm_notebook(enumerate(trainloader), total=len(trainloader)):\n",
        "\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Mettre à zero les gradients des poids du modèle\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = crit(outputs, labels)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            running_loss.append(loss.item())\n",
        "            running_acc.append((predicted == labels).sum().item() / labels.size(0))\n",
        "\n",
        "            # calculer une moyenne\n",
        "            if i % loss_every:\n",
        "                losses.append(np.mean(running_loss))\n",
        "                acc.append(np.mean(running_acc))\n",
        "\n",
        "                running_loss = []\n",
        "                running_acc = []\n",
        "\n",
        "        test_acc = accuracy(testloader, model)\n",
        "        print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2)\n",
        "    axes[0].plot(losses)\n",
        "    axes[1].plot(acc)\n",
        "\n",
        "    axes[0].set_ylabel(\"Train loss\")\n",
        "    axes[1].set_ylabel(\"Train acc\")\n",
        "    plt.show()\n",
        "    print('Apprentissage terminé')\n",
        "\n",
        "\n",
        "def accuracy(loader, model):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        loader: data loader sur lequel on veut calculer une accuracy\n",
        "        model\n",
        "    Returns:\n",
        "        Accuracy\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # remove potential dropout, ...\n",
        "        n_correct = 0\n",
        "        n_total = 0\n",
        "        for i, data in tqdm_notebook(enumerate(loader), total=len(loader)):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            n_correct += (predicted == labels).sum()\n",
        "            n_total += labels.size(0)\n",
        "        return n_correct / n_total\n",
        "\n",
        "\n",
        "def validate(loader, model):\n",
        "    \"\"\"\n",
        "    Plot des predictions faites avec model, affiche l'accuracy\n",
        "    \"\"\"\n",
        "    dataiter = iter(loader)\n",
        "    # Get one batch of data\n",
        "    images, labels = next(dataiter)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    accuracy_model = accuracy(loader, model)\n",
        "\n",
        "    # print images\n",
        "    print(f'Accuracy: {accuracy_model.detach().cpu().item():.3f}')\n",
        "\n",
        "    imshow(images[:4].detach().cpu(), labels[:4], predicted_labels=predictions[:4])\n"
      ],
      "metadata": {
        "id": "ME1CEPK-Bfmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train sur le train avec labels (les 40 % du train supervisé)"
      ],
      "metadata": {
        "id": "BF7p8xDOD42g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "fXf142GVDl_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(testloader, train_loader_labeled, net, optimizer, criterion, n_epoch=5)"
      ],
      "metadata": {
        "id": "aGoc0yMFELZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(testloader, net)"
      ],
      "metadata": {
        "id": "_YHPtX71EO0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utiliser le modèle sur le train unlabeled et utiliser les labels prédits"
      ],
      "metadata": {
        "id": "GpknPkoLHs4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_dataset(loader, model):\n",
        "    \"\"\"\n",
        "    Retourne les prédictions sur un subset donné par loader\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        all_labels = []\n",
        "        for i, data in tqdm_notebook(enumerate(loader), total=len(loader)):\n",
        "\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            all_labels.append(predicted)\n",
        "        return torch.cat(all_labels, dim=0)\n"
      ],
      "metadata": {
        "id": "d7KmH0gsFuMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = label_dataset(train_loader_unlabeled, net)"
      ],
      "metadata": {
        "id": "rmUfJ5dMICHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "id": "LjFZzcvkIGVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remplaçons les labels dans trainset par les labels prédits, souvent appelées des \"pseudo-labels\", pour les exemples unlabeled"
      ],
      "metadata": {
        "id": "Zwwz19r0IOxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k, index in enumerate(indices_unlabeled):\n",
        "    trainset.targets[index] = labels[k].detach().item()"
      ],
      "metadata": {
        "id": "7greesJZIT6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entraînement d'un modèle avec la partie labeled + la partie unlabeled avec les \"pseudo-labels\""
      ],
      "metadata": {
        "id": "1WvuSWEUJ0hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = Net().to(device)\n",
        "optimizer = optim.SGD(net2.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "zg_pEqqQIolo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(testloader, trainloader, net2, optimizer, criterion, n_epoch=5)"
      ],
      "metadata": {
        "id": "yrQqDYBpKcjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(testloader, net2)"
      ],
      "metadata": {
        "id": "14R32OGILG8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'accuracy doit être meilleure, le pseudo-labeling aide !"
      ],
      "metadata": {
        "id": "oyP9gWqeMZCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparaison avec un modèle entraîné sur 100 % du train avec les vraies labels"
      ],
      "metadata": {
        "id": "qr74eTh3OTra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net3 = Net().to(device)\n",
        "optimizer = optim.SGD(net3.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "183UdEoWMOSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "7WfnBfKxOoAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(testloader, trainloader, net3, optimizer, criterion, n_epoch=5)"
      ],
      "metadata": {
        "id": "P4nNHMrBOw1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On obtient environ 10 points de mieux quand même que précedemment !"
      ],
      "metadata": {
        "id": "Qf5xi9H-a5P7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# À faire"
      ],
      "metadata": {
        "id": "6mzVFw90bEvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quelques idées d'expérimentations :\n",
        "\n",
        "\n",
        "\n",
        "*   Baisser à 20% puis 10% la proportion de données avec labels\n",
        "*   Revenir à 40 % mais après avoir fait des prédictions sur les 60 % restant, sélectionner parmi ces 60 % uniquement les exemples dont la confiance (la probabilité associée à la classe prédite par le réseau) est supérieure à un seuil qui vous choississez, par exemple 0.9.\n",
        "*   Tester avec un ResNet pré-entraîné ou non\n",
        "\n"
      ],
      "metadata": {
        "id": "1x8MhnaQbHKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net4 = Net().to(device)\n",
        "optimizer = optim.SGD(net4.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "mseYem1MO0cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(testloader, train_loader_labeled, net4, optimizer, criterion, n_epoch=5)"
      ],
      "metadata": {
        "id": "-QH2O0n5C-TG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}